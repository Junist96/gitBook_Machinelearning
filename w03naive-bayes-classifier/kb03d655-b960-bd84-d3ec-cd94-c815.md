# 확률 분포 추정 

밀도 추정 : 
- 데이터로 부터 변수가 가질 수 있는 모든 값의 밀도(확률)을 추정
- 해당 변수에서 관측된 몇가지 '데이터'로부터 변수가 가질 수 있는 모든 값들에 대한 밀도(확률)를 추정하는 것 
- eg.  나무의 색에서 갈색이 나타날 확률은 높은 반면 파란색이 나타날 확률은 낮다는걸 수학적으로 추정하는것이에요.

## 0. 활용 - 베이즈 정리에서 우도값 유추시 
베이즈 정리 = $$P(\omega_i \mid X ) = \frac{p(X\mid \omega_i)P(\omega_i}{p(X)} = \frac{우도 \times 사전확률}{p(X)}$$

- 베이즈 정리를 완성 하려면 `우도` 값을 알아야함
- 우도값은 데이터의 분포를 가정할수 있다면 쉽게 가능 
    - 쉬운 이유 : 분포의 매개 변수만 알면 가능 


확률 분포 추정 하는법
![](http://i.imgur.com/3RQirUn.png)

모수적 방법 : 특정한 분포를 따른다고 가정하고 밀도함수의 **파라미터(모수, eg:평균, 분산)**를 추정하는 방법 
- MAP: 최대 사후 확률 
- ML/MLE : 최대 우도 

비모수적 방법 : 어떠한 분포 형태도 가정하지 않고, 직접 밀도 함수를 유도하는 방법 
- 히스토 그램 
- K-NNR
- 파첸의 창 = 커널 밀도 추정(KDE) 



## 1. 모수적 분포 
- 사전 확률 고려 유무

- Parametric 밀도추정
    - 미리 pdf(probability density function)에 대한 모델을 정해놓고 
    - 데이터들로부터 모델의 파라미터만 추정하는 방식이다. 

예를 들어, '일일 교통량'이 정규분포를 따른다고 가정해 버리면 관측된 데이터들로부터 **평균**과 **분산**만 구하면 되기 때문에 밀도추정 문제가 비교적 간단한 문제가 되어 버린다.


### 1.1 최대 우도(ML)
- 1992년 R.A. Fisher 제안

- 사전 확률 고려 안함

- 최대 우도(ML)는 일어날 가능성(우도)이 가장 큰 것을 나타냄
    - 즉, 관측된 랜덤 표본에 대한 여러 가설 중 관측결과에 따른 우도함수 값이 최대인 것

- 최대 우도 추정치(MLE: ML Estimator)
    - L($$\Phi$$)를 최대로하는 $$\Phi$$ 값에 대한 추정치를 $$\hat\Phi$$  이라하면,
    - 이때의 $$\hat\Phi$$를 최대우도 추정치 또는 최대 가능도 추정량 (ML Estimator, MLE) 라고함

- 확률 추정 문제 = 최대 우도를 갖는 매개 변수를 찾는 문제 = 최대 우도 방법(ML method)
    - 즉, 주어진 X를 발생 시켰을때 가능성이 가장 높은 매개변수 집합($$\Phi$$)를 찾아라 

![](http://i.imgur.com/vZTi68X.png)
위 예에서 
- P(X| Θ1)>P(X| Θ2)
- 최대 우도를 갖는 Θ는?





###### 공식 : $$ML\ method = \hat\Phi = argmax_\Phi p(X|\Phi)$$

###### 문제 풀이 

|원식|$$argmax_\Phi p(X|\Phi)$$|
|-|-|
|풀어쓰기|![](http://i.imgur.com/CURnf16.png)<br>- $$X={x_1,x_1,..,x_N}$$|
|로그 우도 변환($$\ln$$취하기)|![](http://i.imgur.com/yhBVK32.png)<br>- $$\prod{}{} \rightarrow \sum{}{}$$로 변한건 Log의 곱성질 때문인가?|
|최적화 문제 이므로 미분 이용|![](http://i.imgur.com/36fk8Wr.png)<br>- 최적문제 : L($$\Phi$$)의 도함수를 0으로 두고 풀어 구한 답이 $$\hat\Phi$$

###### ML 활용 가능 알고리즘 
- EM 알고리즘 
- Baum-Welch 알고리즘

> ML은 메타 휴리스틱(=응용에 따라 내부 알고리즘 대체) 이므로 



### 1.2 MAP방법

- 사전 확률 고려함 

- ML은 P($$\Phi$$)가 균일하다고 가정하고 있다.(사전확률 고려 안함)

- 만약 P($$\Phi$$) 정보가 사용가능하고 균일 하지 않다면 P($$\Phi$$)를 식에 추가 하여야 한다. 

![](http://i.imgur.com/R6Nul8J.png)

식에서 P($$x_i \mid \Phi$$)를 우도로 , P($$\Phi$$)를 사전 확률로 본다면 P($$x_i \mid \Phi$$)P($$\Phi$$)는 사후확률로 간주 할수 있다. 
- 이 수식을 풀어서 최적의 매개 변수를 찾는 방법을 MAP라 한다. 

||ML방법|MAP방법|
|-|-|-|
|사전확률|균일|균일하지 않음|
|공식|![](http://i.imgur.com/yhBVK32.png)|![](http://i.imgur.com/R6Nul8J.png)|
|최적해 위치가 다름|![](http://i.imgur.com/T5qe9aZ.png)|![](http://i.imgur.com/qsTiGif.png)<br>- 사전 확률이 균일하지 않은 영향을 받아 최적해가 오른쪽으로 이동|





## 2. 비 모수적 방법 
- 창의 크기 고정 유무 

### 2.1 히스토 그램 

히스토그램 방법은 bin의 경계에서 불연속성이 나타난다는 점, bin의 크기 및 시작 위치에 따라서 히스토그램이 달라진다는 점, 고차원(high dimension) 데이터에는 메모리 문제 등으로 사용하기 힘들다는 점 등의 문제점


출처: http://darkpgmr.tistory.com/147 [다크 프로그래머]

### 2.2 파젠 창(커널 밀도 추정)

- 커널함수(kernel function)를 이용하여 히스토그램 방법의 문제점을 개선한 방법

    - 커널함수(kernel function): 원점을 중심으로 대칭이면서 적분값이 1인 non-negative 함수 (eg. 가우시언함수)

- 고차원이 되었을 때의 문제에서는 여전히 자유롭지 못합니다.
    - 해결 : KNN
    
    https://medium.com/mathpresso/mathpresso-%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EC%8A%A4%ED%84%B0%EB%94%94-14-%EB%B0%80%EB%8F%84-%EC%B6%94%EC%A0%95-density-estimation-38fd7ef729bb

http://carstart.tistory.com/


### 2.3 K-최근접 이웃 

## 3. 혼합모델(두개 이상의 분포) 